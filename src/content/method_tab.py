import gradio as gr
from src.utils import get_base64_image

def method_tab():
    with gr.Tab("锔 Metoda"):
        with gr.Column(elem_classes="method-tab"):
            gr.HTML('<div style="font-size: 40px; font-family: Myriad, sans-serif; font-weight: bold; text-align: left;">锔 Metoda</div>')

            gr.HTML("""
                <div style="font-size: 18px; font-family: Myriad, sans-serif;">
                Proces rozpoczto od oczyszczenia nagra z zak贸ce ta przy u偶yciu modelu Demucs, kt贸ry umo偶liwi skuteczne wydzielenie sygnau mowy. Nastpnie zastosowano Mossformer2 do separacji m贸wc贸w, co pozwolio rozdzieli wypowiedzi r贸偶nych os贸b w nagraniu. Transkrypcja i segmentacja audio zostay przeprowadzone za pomoc modelu Whisper, znanego z wysokiej jakoci rozpoznawania mowy. Otrzymane wypowiedzi pogrupowano przy u偶yciu algorytmu DBSCAN, co uatwio identyfikacj sp贸jnych segment贸w konwersacyjnych.
                <br><br>
                Do tumaczenia wykorzystano polski wielojzyczny model jzykowy Bielik, kt贸ry dobrze radzi sobie z przekadem tekst贸w. Jako tumacze oceniano przy u偶yciu metryk COMET, BERTScore i BLEU, zapewniajcych obiektywn ocen pod wzgldem zgodnoci semantycznej i pynnoci.
                <br><br>
                Syntez mowy zrealizowano przy u偶yciu modelu XTTS-v2, obsugujcego 17 jzyk贸w i umo偶liwiajcego generowanie naturalnego gosu na podstawie jedynie 6-sekundowego nagrania referencyjnego. Zosta on wybrany ze wzgldu na dobr jako d藕wiku, szybko dziaania oraz lepsz kompatybilno z jzykiem polskim ni偶 inne dostpne modele. Na kocu przeprowadzono subiektywn ocen kocowego d藕wiku w formie test贸w odsuchowych.
                <br><br>
                Na poni偶szym schemacie przedstawiono szczeg贸owy przebieg procesu.
                </div>
            """)

            img_data = get_base64_image("assets/schema.png")
            schema_html = f"""
            <div style="display: flex; justify-content: center; padding: 20px;">
                <img src="{img_data}" 
                    style="
                        width: 100%;
                        max-width: 1000px;
                        border: none;
                        object-fit: contain;
                    " 
                    alt="Schemat procesu"
                />
            </div>
            """
            gr.HTML(schema_html)
            gr.HTML('<div style="text-align: center; font-size: 18px; font-family: Myriad, sans-serif;"><strong>Schemat 1.</strong> Przebieg procesu przetwarzania nagrania.</div>')
            
            gr.HTML('<div style="font-size: 40px; font-family: Myriad, sans-serif; font-weight: bold; text-align: left;"> Wyniki</div>')

            gr.HTML('<div style="font-size: 40px; font-family: Myriad, sans-serif; font-weight: bold; text-align: left;"> Nagrania przykadowe</div>')
            with gr.Row():
                with gr.Column():
                    gr.Audio("examples/0x000f7780.wav", label="Nagranie 1", type="filepath")
                with gr.Column():
                    gr.Audio("examples/0x000faf94.wav", label="Nagranie 2", type="filepath")
            with gr.Row():
                with gr.Column():
                    gr.Audio("examples/0x0006de19.wav", label="Nagranie 3", type="filepath")
                with gr.Column():
                    gr.Audio("examples/0x0008d8e5.wav", label="Nagranie 4", type="filepath")
            with gr.Row():
                with gr.Column():
                    gr.Audio("examples/0x0011ce99.wav", label="Nagranie 5", type="filepath")
                with gr.Column():
                    gr.Audio("examples/0x0011cedc.wav", label="Nagranie 6", type="filepath")
            with gr.Row():
                with gr.Column():
                    gr.Audio("examples/dialogue_1.wav", label="Dialog 1", type="filepath")
                with gr.Column():
                    gr.Audio("examples/dialogue_9.wav", label="Dialog 2", type="filepath")
